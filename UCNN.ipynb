{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67208051",
   "metadata": {},
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì „ìš© ë…¸íŠ¸ë¶\n",
    "\n",
    "**âš ï¸ ì´ ë…¸íŠ¸ë¶ì€ í•™ìŠµ ì—†ì´ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.**\n",
    "\n",
    "ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ì²˜ëŸ¼ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì…ë ¥í–ˆì„ ë•Œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤:\n",
    "- **U-Net ëª¨ë¸**: ê²°í•¨ ê²€ì¶œ (ì´ë¯¸ì§€ì— ê²°í•¨ì´ ìˆëŠ”ì§€ íŒë‹¨)\n",
    "- **CNN ëª¨ë¸**: ê²°í•¨ ìœ í˜• ë¶„ë¥˜ (ê²°í•¨ì´ ìˆë‹¤ë©´ ì–´ë–¤ ìœ í˜•ì¸ì§€ ë¶„ë¥˜)\n",
    "\n",
    "## ì§„í–‰ ìˆœì„œ\n",
    "1. **í™˜ê²½ ì„¤ì •**: GPU í™•ì¸ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "2. **ëª¨ë¸ ë¡œë“œ**: ë¯¸ë¦¬ í•™ìŠµëœ U-Netê³¼ CNN ëª¨ë¸ ë¡œë“œ\n",
    "3. **í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„**: í‰ê°€í•  ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„\n",
    "4. **U-Net í…ŒìŠ¤íŠ¸**: ê²°í•¨ ê²€ì¶œ ì„±ëŠ¥ í‰ê°€\n",
    "5. **CNN í…ŒìŠ¤íŠ¸**: ê²°í•¨ ìœ í˜• ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€\n",
    "6. **ê²°ê³¼ ì‹œê°í™”**: ê²€ì¶œ ë° ë¶„ë¥˜ ê²°ê³¼ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU í™•ì¸\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow GPU í™•ì¸\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print('TensorFlow GPU:', 'Found GPU at: {}'.format(device_name) if device_name == '/device:GPU:0' else 'GPU not found.')\n",
    "\n",
    "# PyTorch GPU í™•ì¸\n",
    "print('PyTorch GPU:', f'Found GPU: {torch.cuda.get_device_name(0)}' if torch.cuda.is_available() else 'GPU not found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ import\n",
    "from utils.cnn.defect_detection import scan_data_directory, load_image_for_cnn, get_defect_type_from_npy\n",
    "from utils.cnn.classifier import load_cnn_model\n",
    "from utils.cnn.dataset_functions import get_label_mapping, create_cnn_dataset, unwrap_client_data\n",
    "from utils.u_net.dataset_functions import create_dataset, unwrap_client_data as unwrap_unet_data\n",
    "from utils.u_net.image_processing import unsplit_image_mask\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "data_dir = 'data'  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ë°ì´í„° í´ë” ê²½ë¡œ\n",
    "unet_model_path = 'saved_models/FL_2_5_32_8e05_HoldoutPart06_1.h5'  # ë¯¸ë¦¬ í•™ìŠµëœ U-Net ëª¨ë¸ ê²½ë¡œ\n",
    "cnn_model_path = 'saved_models/CNN_FL_1_1_32_1e04_HoldoutPart06.pth'  # ë¯¸ë¦¬ í•™ìŠµëœ CNN ëª¨ë¸ ê²½ë¡œ\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •\n",
    "max_files = None  # Noneì´ë©´ ì „ì²´ ì‚¬ìš©, ìˆ«ìë¥¼ ì§€ì •í•˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)\n",
    "\n",
    "print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í„°ë¦¬: {data_dir}\")\n",
    "print(f\"ğŸ¤– U-Net ëª¨ë¸ ê²½ë¡œ: {unet_model_path}\")\n",
    "print(f\"ğŸ¤– CNN ëª¨ë¸ ê²½ë¡œ: {cnn_model_path}\")\n",
    "print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°œìˆ˜: {max_files if max_files else 'ì „ì²´'}\")\n",
    "print(\"\\nâš ï¸ ì°¸ê³ : ì´ ë…¸íŠ¸ë¶ì€ í•™ìŠµ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1ë‹¨ê³„: ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ (í•™ìŠµ ì—†ìŒ)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"1ë‹¨ê³„: ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\")\n",
    "print(\"=\"*60)\n",
    "print(\"âš ï¸ í•™ìŠµ ì—†ì´ ì €ì¥ëœ ëª¨ë¸ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# U-Net ëª¨ë¸ ë¡œë“œ (TensorFlow)\n",
    "print(\"\\n[1-1] U-Net ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "unet_model = tf.keras.models.load_model(unet_model_path, compile=False)\n",
    "print(\"âœ“ U-Net ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"  ì…ë ¥ shape: {unet_model.input_shape}\")\n",
    "print(f\"  ì¶œë ¥ shape: {unet_model.output_shape}\")\n",
    "\n",
    "# CNN ëª¨ë¸ ë¡œë“œ (PyTorch)\n",
    "print(\"\\n[1-2] CNN ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn_model = load_cnn_model(cnn_model_path, device=device)\n",
    "print(\"âœ“ CNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in cnn_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf23509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (í•™ìŠµ ì—†ìŒ)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\")\n",
    "print(\"=\"*60)\n",
    "print(\"âš ï¸ í•™ìŠµ ì—†ì´ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ë°ì´í„°ë§Œ ì¤€ë¹„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ë°ì´í„° ë””ë ‰í„°ë¦¬ ìŠ¤ìº”\n",
    "print(\"\\n[2-1] ë°ì´í„° ë””ë ‰í„°ë¦¬ ìŠ¤ìº” ì¤‘...\")\n",
    "file_list = scan_data_directory(data_dir)\n",
    "print(f\"âœ“ ì´ {len(file_list)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬\")\n",
    "\n",
    "# ë°ì´í„° ê°œìˆ˜ ì œí•œ ì ìš© (í…ŒìŠ¤íŠ¸ìš©)\n",
    "if max_files is not None and max_files > 0:\n",
    "    file_list = file_list[:max_files]\n",
    "    print(f\"âœ“ ë°ì´í„° ê°œìˆ˜ ì œí•œ: {len(file_list)}ê°œ íŒŒì¼ ì‚¬ìš©\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì • (ëª¨ë“  íŒŒì¼ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©)\n",
    "# ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ìƒˆë¡œìš´ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ í‰ê°€\n",
    "import random\n",
    "\n",
    "random.seed(42)  # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
    "test_client_id = 6\n",
    "num_clients = 8\n",
    "\n",
    "# ë ˆì´ë¸” ë§¤í•‘ ìƒì„±ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ êµ¬ì¡° ìƒì„± (ëª¨ë¸ í•™ìŠµ ì‹œì™€ ë™ì¼í•œ êµ¬ì¡° ìœ ì§€)\n",
    "# ì‹¤ì œë¡œëŠ” ëª¨ë“  íŒŒì¼ì„ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, ë ˆì´ë¸” ë§¤í•‘ì„ ìœ„í•´ êµ¬ì¡° ìœ ì§€\n",
    "train_clients = [f'client{i}' for i in range(1, num_clients + 1) if i != test_client_id]\n",
    "\n",
    "# ì „ì²´ íŒŒì¼ì„ í´ë¼ì´ì–¸íŠ¸ì— ë¶„ë°° (ë ˆì´ë¸” ë§¤í•‘ ìƒì„±ì„ ìœ„í•´ êµ¬ì¡°ë§Œ ìœ ì§€)\n",
    "random.shuffle(file_list)\n",
    "files_per_client = len(file_list) // len(train_clients)\n",
    "\n",
    "clientIdentifierDict = {}\n",
    "test_files = []\n",
    "\n",
    "start_idx = 0\n",
    "for i, client_id in enumerate(train_clients):\n",
    "    if i < len(train_clients) - 1:\n",
    "        end_idx = start_idx + files_per_client\n",
    "    else:\n",
    "        end_idx = len(file_list)\n",
    "    \n",
    "    client_files = file_list[start_idx:end_idx]\n",
    "    clientIdentifierDict[client_id] = client_files\n",
    "    start_idx = end_idx\n",
    "\n",
    "# ëª¨ë“  íŒŒì¼ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš© (ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤)\n",
    "test_files = file_list\n",
    "clientIdentifierDict[f'client{test_client_id}'] = test_files\n",
    "\n",
    "print(f\"\\nâœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:\")\n",
    "print(f\"  í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(test_files)}ê°œ\")\n",
    "print(f\"  (ëª¨ë“  íŒŒì¼ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©)\")\n",
    "\n",
    "# ë ˆì´ë¸” ë§¤í•‘ ìƒì„± (CNN ëª¨ë¸ê³¼ ë™ì¼í•œ ë§¤í•‘ í•„ìš”)\n",
    "print(\"\\n[2-2] ë ˆì´ë¸” ë§¤í•‘ ìƒì„± ì¤‘...\")\n",
    "label_mapping, num_classes = get_label_mapping(data_dir, clientIdentifierDict)\n",
    "print(f\"âœ“ ë ˆì´ë¸” ë§¤í•‘ ì™„ë£Œ: {num_classes}ê°œ í´ë˜ìŠ¤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3ë‹¨ê³„: U-Net ëª¨ë¸ í…ŒìŠ¤íŠ¸ - ê²°í•¨ ê²€ì¶œ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3ë‹¨ê³„: U-Net ê²°í•¨ ê²€ì¶œ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "print(\"âš ï¸ í•™ìŠµ ì—†ì´ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# U-Netìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "tileSize = 128\n",
    "defect_threshold = 0.01\n",
    "\n",
    "test_client_id = 6\n",
    "test_clients = [f'client{test_client_id}']\n",
    "test_files = clientIdentifierDict[f'client{test_client_id}']\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ íŒŒì¼ ê·¸ë£¹ ìƒì„±\n",
    "test_file_groups = {'test': test_files}\n",
    "\n",
    "imagePath0 = f'{data_dir}/0/'\n",
    "imagePath1 = f'{data_dir}/1/'\n",
    "npyPath = f'{data_dir}/annotations/'\n",
    "\n",
    "print(\"\\n[3-1] U-Net í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "testImageDict, testMaskDict = create_dataset(\n",
    "    test_file_groups,\n",
    "    imagePath0,\n",
    "    imagePath1,\n",
    "    npyPath,\n",
    "    tileSize=tileSize\n",
    ")\n",
    "print(\"âœ“ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "# U-Net ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"\\n[3-2] U-Net ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\")\n",
    "testImages, testMasks = unwrap_unet_data(testImageDict, testMaskDict, ['test'])\n",
    "print(f\"ì´ {testImages.shape[0]}ê°œ íƒ€ì¼ ì˜ˆì¸¡ ì¤‘...\")\n",
    "\n",
    "predictedImages = unet_model.predict(testImages, verbose=0)\n",
    "predictedMask = tf.argmax(predictedImages, axis=-1)\n",
    "\n",
    "# ê° ì´ë¯¸ì§€ë³„ë¡œ ê²°ê³¼ ìˆ˜ì§‘\n",
    "unet_results = []\n",
    "num_tiles_per_image = 25  # 640x640 = 5*5 = 25 íƒ€ì¼\n",
    "curr_idx = 0\n",
    "\n",
    "for file_name in test_files:\n",
    "    prev_idx = curr_idx\n",
    "    curr_idx = prev_idx + num_tiles_per_image\n",
    "    \n",
    "    # íƒ€ì¼ ì¬êµ¬ì„±\n",
    "    imageheight, imagewidth = 5*128, 5*128  # 640x640\n",
    "    fullPredictedMask = unsplit_image_mask(\n",
    "        predictedMask[prev_idx:curr_idx],\n",
    "        imageheight,\n",
    "        imagewidth\n",
    "    )\n",
    "    \n",
    "    # ê²°í•¨ ê²€ì¶œ\n",
    "    defect_mask = fullPredictedMask[0, :, :, 0].numpy()\n",
    "    defect_ratio = np.sum(defect_mask == 2) / defect_mask.size if defect_mask.size > 0 else 0.0\n",
    "    has_defect = defect_ratio > defect_threshold\n",
    "    \n",
    "    # ì‹¤ì œ ë ˆì´ë¸” í™•ì¸\n",
    "    npy_path = Path(npyPath) / f\"{file_name}.npy\"\n",
    "    actual_defect_type, _ = get_defect_type_from_npy(str(npy_path))\n",
    "    actual_has_defect = actual_defect_type is not None\n",
    "    \n",
    "    unet_results.append({\n",
    "        'file_name': file_name,\n",
    "        'predicted_has_defect': has_defect,\n",
    "        'actual_has_defect': actual_has_defect,\n",
    "        'defect_ratio': defect_ratio,\n",
    "        'mask': defect_mask\n",
    "    })\n",
    "    \n",
    "    if curr_idx >= len(predictedMask):\n",
    "        break\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "true_positives = sum(1 for r in unet_results if r['predicted_has_defect'] and r['actual_has_defect'])\n",
    "false_positives = sum(1 for r in unet_results if r['predicted_has_defect'] and not r['actual_has_defect'])\n",
    "false_negatives = sum(1 for r in unet_results if not r['predicted_has_defect'] and r['actual_has_defect'])\n",
    "true_negatives = sum(1 for r in unet_results if not r['predicted_has_defect'] and not r['actual_has_defect'])\n",
    "\n",
    "unet_precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "unet_recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "unet_f1_score = 2 * (unet_precision * unet_recall) / (unet_precision + unet_recall) if (unet_precision + unet_recall) > 0 else 0\n",
    "unet_accuracy = (true_positives + true_negatives) / len(unet_results) if len(unet_results) > 0 else 0\n",
    "\n",
    "print(f\"\\nâœ“ U-Net ê²€ì¶œ ì™„ë£Œ!\")\n",
    "print(f\"\\n[ê²€ì¶œ ì„±ëŠ¥]\")\n",
    "print(f\"  ì •í™•ë„ (Accuracy): {unet_accuracy:.4f}\")\n",
    "print(f\"  ì •ë°€ë„ (Precision): {unet_precision:.4f}\")\n",
    "print(f\"  ì¬í˜„ìœ¨ (Recall): {unet_recall:.4f}\")\n",
    "print(f\"  F1 ì ìˆ˜: {unet_f1_score:.4f}\")\n",
    "print(f\"\\n[ê²€ì¶œ ê²°ê³¼]\")\n",
    "print(f\"  True Positives: {true_positives}\")\n",
    "print(f\"  False Positives: {false_positives}\")\n",
    "print(f\"  False Negatives: {false_negatives}\")\n",
    "print(f\"  True Negatives: {true_negatives}\")\n",
    "print(f\"  ì´ í…ŒìŠ¤íŠ¸ íŒŒì¼: {len(unet_results)}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4ë‹¨ê³„: CNN ëª¨ë¸ í…ŒìŠ¤íŠ¸ - ê²°í•¨ ìœ í˜• ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4ë‹¨ê³„: CNN ê²°í•¨ ìœ í˜• ë¶„ë¥˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "print(\"âš ï¸ í•™ìŠµ ì—†ì´ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# CNNìš© í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "print(\"\\n[4-1] CNN í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "target_size = (640, 640)\n",
    "testImageDict, testLabelDict = create_cnn_dataset(\n",
    "    {f'client{test_client_id}': test_files},\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    label_mapping=label_mapping\n",
    ")\n",
    "print(\"âœ“ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "testImages, testLabels = unwrap_client_data(testImageDict, testLabelDict, [f'client{test_client_id}'])\n",
    "testImages = testImages.to(device)\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ shape: {testImages.shape}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” shape: {testLabels.shape}\")\n",
    "\n",
    "# CNN ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"\\n[4-2] CNN ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\")\n",
    "batch_size = 32\n",
    "predictions = []\n",
    "probabilities_list = []\n",
    "\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(testImages), batch_size):\n",
    "        batch_images = testImages[i:i+batch_size]\n",
    "        outputs = cnn_model(batch_images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        probabilities_list.extend(probs.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "probabilities_list = np.array(probabilities_list)\n",
    "test_labels_np = testLabels.numpy()\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "correct = (predictions == test_labels_np).sum()\n",
    "cnn_accuracy = correct / len(test_labels_np)\n",
    "\n",
    "print(f\"\\nâœ“ CNN ë¶„ë¥˜ ì™„ë£Œ!\")\n",
    "print(f\"\\n[ë¶„ë¥˜ ì„±ëŠ¥]\")\n",
    "print(f\"  ì •í™•ë„ (Accuracy): {cnn_accuracy:.4f} ({correct}/{len(test_labels_np)})\")\n",
    "\n",
    "# ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ë§Œ ì¶”ì¶œ\n",
    "unique_labels = np.unique(np.concatenate([test_labels_np, predictions]))\n",
    "unique_labels = np.sort(unique_labels)\n",
    "print(f\"\\n  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤: {unique_labels.tolist()}\")\n",
    "print(f\"  ì´ í´ë˜ìŠ¤ ìˆ˜: {len(unique_labels)}ê°œ (ì „ì²´ {num_classes}ê°œ ì¤‘)\")\n",
    "\n",
    "# ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ë§Œ ì‚¬ìš©)\n",
    "print(f\"\\n[ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸]\")\n",
    "target_names = [f'Class_{i}' for i in unique_labels]\n",
    "print(classification_report(test_labels_np, predictions, \n",
    "                          labels=unique_labels,\n",
    "                          target_names=target_names,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Confusion Matrix ìƒì„± (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ë§Œ ì‚¬ìš©)\n",
    "cm = confusion_matrix(test_labels_np, predictions, labels=unique_labels)\n",
    "print(f\"\\n[Confusion Matrix]\")\n",
    "print(f\"í´ë˜ìŠ¤: {unique_labels.tolist()}\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™”\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# unique_labelsê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ëŒ€ë¹„ (Cell 7ì„ ë¨¼ì € ì‹¤í–‰í•´ì•¼ í•¨)\n",
    "if 'unique_labels' not in locals():\n",
    "    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ë§Œ ì¶”ì¶œ\n",
    "    unique_labels = np.unique(np.concatenate([test_labels_np, predictions]))\n",
    "    unique_labels = np.sort(unique_labels)\n",
    "    print(f\"\\n  ì°¸ê³ : í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤: {unique_labels.tolist()}\")\n",
    "\n",
    "# 5-1: U-Net ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”\n",
    "print(\"\\n[5-1] U-Net ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# ê²°í•¨ì´ ê²€ì¶œëœ ì´ë¯¸ì§€ ëª‡ ê°œ ì„ íƒ\n",
    "defect_detected = [r for r in unet_results if r['predicted_has_defect']]\n",
    "sample_results = defect_detected[:6] if len(defect_detected) >= 6 else defect_detected\n",
    "\n",
    "for idx, result in enumerate(sample_results):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "    \n",
    "    file_name = result['file_name']\n",
    "    img0_path = Path(imagePath0) / f\"{file_name}.jpg\"\n",
    "    img1_path = Path(imagePath1) / f\"{file_name}.jpg\"\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (Post Fusion)\n",
    "    img = plt.imread(str(img1_path))\n",
    "    axes[idx].imshow(img, cmap='gray')\n",
    "    axes[idx].set_title(f\"{file_name}\\nê²°í•¨ ë¹„ìœ¨: {result['defect_ratio']:.3f}\\n\"\n",
    "                       f\"ì˜ˆì¸¡: {'ê²°í•¨' if result['predicted_has_defect'] else 'ì •ìƒ'}\\n\"\n",
    "                       f\"ì‹¤ì œ: {'ê²°í•¨' if result['actual_has_defect'] else 'ì •ìƒ'}\",\n",
    "                       fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# ë¹ˆ subplot ì œê±°\n",
    "for idx in range(len(sample_results), 6):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('U-Net ê²°í•¨ ê²€ì¶œ ê²°ê³¼ (ìƒ˜í”Œ)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-2: CNN ë¶„ë¥˜ Confusion Matrix ì‹œê°í™”\n",
    "print(\"\\n[5-2] CNN ë¶„ë¥˜ Confusion Matrix ì‹œê°í™”\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[f'Class_{i}' for i in unique_labels],\n",
    "            yticklabels=[f'Class_{i}' for i in unique_labels])\n",
    "plt.title('CNN ê²°í•¨ ìœ í˜• ë¶„ë¥˜ Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('ì˜ˆì¸¡ ë ˆì´ë¸”')\n",
    "plt.ylabel('ì‹¤ì œ ë ˆì´ë¸”')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-3: í´ë˜ìŠ¤ë³„ ì •í™•ë„ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ë§Œ)\n",
    "print(\"\\n[5-3] í´ë˜ìŠ¤ë³„ ë¶„ë¥˜ ì •í™•ë„\")\n",
    "\n",
    "class_accuracies = []\n",
    "for i in unique_labels:\n",
    "    mask = test_labels_np == i\n",
    "    if mask.sum() > 0:\n",
    "        class_acc = (predictions[mask] == test_labels_np[mask]).sum() / mask.sum()\n",
    "        class_accuracies.append(class_acc)\n",
    "    else:\n",
    "        class_accuracies.append(0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(unique_labels)), class_accuracies, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('í´ë˜ìŠ¤', fontsize=12)\n",
    "plt.ylabel('ì •í™•ë„', fontsize=12)\n",
    "plt.title('í´ë˜ìŠ¤ë³„ ë¶„ë¥˜ ì •í™•ë„', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(unique_labels)), [f'Class_{i}' for i in unique_labels], rotation=45)\n",
    "plt.ylim([0, 1.1])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ê°’ í‘œì‹œ\n",
    "for i, (bar, acc) in enumerate(zip(bars, class_accuracies)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-4: ì˜ˆì¸¡ í™•ì‹ ë„ ë¶„í¬\n",
    "print(\"\\n[5-4] ì˜ˆì¸¡ í™•ì‹ ë„ ë¶„í¬\")\n",
    "\n",
    "max_probs = probabilities_list.max(axis=1)\n",
    "correct_probs = probabilities_list[np.arange(len(predictions)), predictions]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ì „ì²´ ì˜ˆì¸¡ í™•ì‹ ë„\n",
    "axes[0].hist(max_probs, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('ìµœëŒ€ ì˜ˆì¸¡ í™•ë¥ ', fontsize=12)\n",
    "axes[0].set_ylabel('ë¹ˆë„', fontsize=12)\n",
    "axes[0].set_title('ì „ì²´ ì˜ˆì¸¡ í™•ì‹ ë„ ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# ì •í™•/ì˜¤ë¶„ë¥˜ë³„ í™•ì‹ ë„\n",
    "correct_mask = predictions == test_labels_np\n",
    "axes[1].hist(max_probs[correct_mask], bins=30, alpha=0.7, label='ì •í™•', color='green', edgecolor='black')\n",
    "axes[1].hist(max_probs[~correct_mask], bins=30, alpha=0.7, label='ì˜¤ë¶„ë¥˜', color='red', edgecolor='black')\n",
    "axes[1].set_xlabel('ìµœëŒ€ ì˜ˆì¸¡ í™•ë¥ ', fontsize=12)\n",
    "axes[1].set_ylabel('ë¹ˆë„', fontsize=12)\n",
    "axes[1].set_title('ì •í™•/ì˜¤ë¶„ë¥˜ë³„ ì˜ˆì¸¡ í™•ì‹ ë„', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ì‹œê°í™” ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f33c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6ë‹¨ê³„: ì¢…í•© ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6ë‹¨ê³„: ì¢…í•© ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "print(\"âš ï¸ ì´ ë…¸íŠ¸ë¶ì€ í•™ìŠµ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\\n\")\n",
    "\n",
    "print(\"[U-Net ëª¨ë¸ ì„±ëŠ¥]\")\n",
    "print(f\"  ëª¨ë¸ ê²½ë¡œ: {unet_model_path}\")\n",
    "print(f\"  ê²°í•¨ ê²€ì¶œ ì •í™•ë„: {unet_accuracy:.4f}\")\n",
    "print(f\"  ì •ë°€ë„: {unet_precision:.4f}\")\n",
    "print(f\"  ì¬í˜„ìœ¨: {unet_recall:.4f}\")\n",
    "print(f\"  F1 ì ìˆ˜: {unet_f1_score:.4f}\")\n",
    "\n",
    "print(\"\\n[CNN ëª¨ë¸ ì„±ëŠ¥]\")\n",
    "print(f\"  ëª¨ë¸ ê²½ë¡œ: {cnn_model_path}\")\n",
    "print(f\"  ê²°í•¨ ìœ í˜• ë¶„ë¥˜ ì •í™•ë„: {cnn_accuracy:.4f}\")\n",
    "print(f\"  ì´ í´ë˜ìŠ¤ ìˆ˜: {num_classes}\")\n",
    "print(f\"  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_labels_np)}\")\n",
    "\n",
    "print(\"\\n[í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë³´]\")\n",
    "print(f\"  ì´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(test_files)}\")\n",
    "print(f\"  U-Net ê²€ì¶œ ì™„ë£Œ: {len(unet_results)}ê°œ\")\n",
    "print(f\"  CNN ë¶„ë¥˜ ê°€ëŠ¥ íŒŒì¼: {len(test_labels_np)}ê°œ\")\n",
    "\n",
    "print(\"\\n[ëª¨ë¸ ì •ë³´]\")\n",
    "print(f\"  U-Net ì…ë ¥ shape: {unet_model.input_shape}\")\n",
    "print(f\"  U-Net ì¶œë ¥ shape: {unet_model.output_shape}\")\n",
    "print(f\"  CNN device: {device}\")\n",
    "print(f\"  CNN íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in cnn_model.parameters()):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ! (í•™ìŠµ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰)\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
