# Federated Learning for Additive Manufacturing (FLAM)

이 저장소는 연합 학습 기반의 시맨틱 세그멘테이션을 사용한 적층 제조 결함 검출 프로젝트입니다.

## 프로젝트 개요

본 프로젝트는 여러 클라이언트에 분산된 데이터를 사용하여 연합 학습(Federated Learning) 방식으로 U-Net 모델을 학습시켜 적층 제조 공정의 픽셀 단위 결함을 검출합니다.

## 프로젝트 구조 및 학습 방식

### 데이터 구조 (merged_data)

통합된 데이터는 `merged_data` 폴더에 다음과 같은 구조로 저장되어 있습니다:

```
merged_data/
├── 0/              # Post Spreading Images (.jpg) - 분산 후 이미지
│   ├── 000001.jpg
│   ├── 000002.jpg
│   └── ... (총 693개)
├── 1/              # Post Fusion Images (.jpg) - 융합 후 이미지
│   ├── 000001.jpg
│   ├── 000002.jpg
│   └── ... (총 693개)
└── annotations/    # Segmentation Masks (.npy) - 세그멘테이션 마스크
    ├── 000001.npy
    ├── 000002.npy
    └── ... (총 693개)
```

- **총 데이터 개수**: 693개의 이미지 쌍과 해당 마스크
- **이미지 쌍 구조**: 각 샘플은 Post Spreading 이미지(0/)와 Post Fusion 이미지(1/)로 구성
- **마스크 형식**: NumPy 배열(.npy) 형식의 픽셀 단위 세그멘테이션 레이블

### 클라이언트 분배 전략

데이터는 8개의 클라이언트에 균등하게 분배됩니다:

- **총 파일 수**: 693개
- **클라이언트 수**: 8개

- **학습/테스트 분리**: client6을 테스트 클라이언트로 사용하고, 나머지 7개 클라이언트를 학습에 사용

### 이미지 전처리 및 타일링

1. **이미지 크롭**: 이미지 크기를 타일 크기(128x128)의 배수로 조정
2. **그레이스케일 변환**: RGB 이미지를 그레이스케일로 변환 (채널 수: 3 → 1)
   - 적층 제조 이미지의 경우 색상 정보보다 밝기/명암 정보가 결함 검출에 더 중요
   - 메모리 사용량과 계산 복잡도 감소
   - Post Spreading과 Post Fusion 이미지를 각각 1채널로 변환하여 이후 2채널 입력을 구성하기 위함
3. **이미지 결합**: Post Spreading 이미지와 Post Fusion 이미지를 채널 차원에서 결합하여 2채널 입력 생성
   - 각 이미지를 1채널로 변환한 후 결합하여 (height, width, 2) 형태의 입력 생성
   - 모델이 두 시점(분산 후, 융합 후)의 이미지 차이를 학습할 수 있도록 함
4. **타일 분할**: 각 이미지를 128x128 크기의 타일로 분할
5. **정규화**: 픽셀 값을 [0, 1] 범위로 정규화
6. **마스크 처리**: 
   - 레이블되지 않은 픽셀(-1)을 Powder 클래스(0)로 변환
   - 모든 결함 클래스를 단일 Defect 클래스(2)로 통합

**최종 입력 형식**: (n_tiles, 128, 128, 2)
- n_tiles: 이미지 크기에 따라 달라지는 타일 개수
- 128x128: 타일 크기
- 2: Post Spreading + Post Fusion 이미지 채널

### 세그멘테이션 클래스

모델은 3개의 클래스를 구분합니다:
- **클래스 0 (Powder)**: 분말 영역
- **클래스 1 (Part)**: 부품 영역
- **클래스 2 (Defect)**: 결함 영역 (모든 결함 유형 통합)

### 모델 구조 (U-Net)

U-Net 아키텍처를 사용한 시맨틱 세그멘테이션 모델:

- **입력**: (128, 128, 2) - 타일 단위의 2채널 이미지
- **출력**: (128, 128, 3) - 각 픽셀에 대한 3개 클래스의 로짓(logit) 값
- **구조**: 
  - 인코더: 5단계 다운샘플링 (32 → 64 → 128 → 256 → 512 채널)
  - 디코더: 5단계 업샘플링 (512 → 256 → 128 → 64 → 32 채널)
  - 스킵 연결: 인코더의 특징 맵을 디코더에 연결하여 공간 정보 보존
- **손실 함수**: Sparse Categorical Crossentropy
- **최적화**: Adam optimizer

### 연합 학습 알고리즘 (FedAvg)

본 프로젝트는 Federated Averaging (FedAvg) 알고리즘을 구현합니다:

#### 학습 프로세스

1. **전역 모델 초기화**: 서버에서 U-Net 모델을 초기화

2. **서버 라운드 반복** (SERVER_ROUNDS번):
   - **로컬 학습 단계**:
     - 각 클라이언트는 전역 모델의 복사본을 받음
     - 클라이언트는 자신의 로컬 데이터로 LOCAL_EPOCHS만큼 학습
     - 학습된 모델의 가중치를 서버로 전송
   
   - **서버 집계 단계**:
     - 서버는 모든 클라이언트의 가중치를 수신
     - 각 클라이언트의 데이터 크기에 비례한 가중 평균을 계산
     - 계산된 가중치로 전역 모델 업데이트
   
   - **평가 단계**:
     - 업데이트된 전역 모델을 테스트 데이터셋으로 평가
     - 테스트 손실 및 정확도 기록

#### 가중 평균 계산

각 클라이언트의 가중치는 해당 클라이언트의 데이터 크기(타일 개수)에 비례합니다:

```
w_global = Σ (n_k / N) * w_k
```

- w_global: 전역 모델 가중치
- n_k: 클라이언트 k의 데이터 크기 (타일 개수)
- N: 모든 클라이언트의 총 데이터 크기
- w_k: 클라이언트 k의 로컬 모델 가중치

이 방식은 데이터 크기가 다른 클라이언트 간의 불균형을 자동으로 처리합니다.

#### 하이퍼파라미터

- **SERVER_ROUNDS**: 서버 라운드 수 (전역 모델 업데이트 횟수)
- **LOCAL_EPOCHS**: 각 클라이언트의 로컬 학습 에포크 수
- **LOCAL_BATCH_SIZE**: 로컬 학습 시 배치 크기
- **LOCAL_LEARNING_RATE**: 로컬 학습률

### utils_merge 모듈 구조

프로젝트의 핵심 기능은 `utils_merge` 폴더에 모듈화되어 있습니다:

#### `dataset_functions.py`
- **역할**: 데이터셋 생성 및 클라이언트별 데이터 분배
- **주요 기능**:
  - 클라이언트별 파일 리스트를 기반으로 데이터셋 생성
  - 이미지와 마스크를 타일 단위로 변환하여 딕셔너리로 저장
  - 클라이언트 데이터를 단일 텐서로 결합 (테스트용)
  - Lazy loading 지원 (메모리 효율적 데이터 로딩)

#### `image_processing.py`
- **역할**: 이미지 전처리 및 타일링/역타일링
- **주요 기능**:
  - 이미지 크롭, 그레이스케일 변환, 정규화
  - 이미지를 타일로 분할
  - 타일을 다시 원본 이미지 크기로 재구성
  - 마스크 전처리 (레이블 정규화)

#### `unet.py`
- **역할**: U-Net 모델 아키텍처 정의
- **주요 기능**:
  - U-Net 모델 초기화 및 컴파일
  - 인코더-디코더 구조 구현
  - 스킵 연결 구현

#### `federated_averaging.py`
- **역할**: 연합 학습 알고리즘 구현
- **주요 기능**:
  - FedAvg 알고리즘 실행
  - 클라이언트별 로컬 학습 관리
  - 가중 평균 계산 및 전역 모델 업데이트
  - 학습 과정 추적 (손실, 정확도)

#### `visualization.py`
- **역할**: 학습 결과 시각화
- **주요 기능**:
  - 테스트 데이터셋에 대한 예측 결과 시각화
  - 원본 이미지, 실제 마스크, 예측 마스크 비교
  - MeanIoU (Intersection over Union) 계산 및 출력

### 학습 워크플로우

1. **데이터 준비**: `merged_data` 폴더에서 이미지와 마스크 로드
2. **클라이언트 분배**: 693개 파일을 8개 클라이언트에 분배
3. **데이터 전처리**: 각 이미지를 타일로 분할하고 전처리
4. **모델 초기화**: U-Net 모델 생성
5. **연합 학습 실행**: FedAvg 알고리즘으로 모델 학습
6. **모델 평가**: 테스트 클라이언트로 성능 평가
7. **결과 시각화**: 예측 결과를 시각적으로 확인
8. **모델 저장**: 학습된 모델을 파일로 저장

## 환경 설정

### 1. 의존성 설치

```bash
pip install -r requirements.txt
```

### 2. 데이터 통합

여러 데이터셋을 하나의 `merged_data` 폴더로 통합합니다:

```bash
python new_utils/merge_data_files.py
```

이 스크립트는:
- `data` 폴더의 모든 이미지 파일을 찾아서
- `merged_data` 폴더에 `000001`, `000002`, ... 형식으로 번호를 매겨 저장합니다
- `0`, `1`, `annotations` 폴더 구조를 유지합니다

**출력 예시:**
```
소스 폴더: D:\iot\FLAM\data
출력 폴더: D:\iot\FLAM\merged_data
데이터 구조: data/0/, data/1/, data/annotations/ 직접 구조 감지
  693개의 이미지 파일 발견

총 693개의 파일 그룹 발견
파일 복사 시작...
  진행 중: 100개 파일 처리 완료
  진행 중: 200개 파일 처리 완료
  ...

완료! 총 693개의 파일 그룹을 merged_data 폴더에 복사했습니다.
```

### 3. 대용량 이미지 제거 (선택사항)

500KB 이상의 대용량 이미지를 제거하려면:

```bash
python new_utils/remove_large_images.py
```

## 연합 학습 실행

### 1. 노트북 실행

`Federated_learning_merged_data.ipynb` 노트북을 실행합니다.

### 2. 주요 단계

#### Step 1: GPU 확인 및 설정
첫 번째 셀을 실행하여 GPU 사용 가능 여부를 확인합니다.

#### Step 2: 데이터 경로 설정
```python
imagePath0 = 'merged_data/0/'      # Post Spreading Images
imagePath1 = 'merged_data/1/'       # Post Fusion Images
npyPath = 'merged_data/annotations/' # Annotations
```

#### Step 3: 클라이언트 분배 및 하이퍼파라미터 설정
- 총 파일 개수와 클라이언트 수 설정
- 학습/테스트 클라이언트 분리
- 서버 라운드, 로컬 에포크, 배치 크기, 학습률 등 하이퍼파라미터 설정

#### Step 4: 모델 학습
연합 학습을 시작합니다. 자세한 학습 프로세스는 위의 "연합 학습 알고리즘 (FedAvg)" 섹션을 참조하세요.

### 3. 학습 결과

학습이 완료되면:
- 모델이 `saved_models/` 폴더에 자동으로 저장됩니다
- 파일명 형식: `FL_{SERVER_ROUNDS}_{LOCAL_EPOCHS}_{BATCH_SIZE}_{LR}_HoldoutPart{test_set}.h5`
- 테스트 성능(Loss, Accuracy)이 출력됩니다

## 유틸리티 스크립트

### `new_utils/merge_data_files.py`
여러 데이터셋을 하나로 통합하는 스크립트

### `new_utils/remove_large_images.py`
대용량 이미지 파일을 제거하는 스크립트 (기본값: 500KB 이상)

### `new_utils/convert_tif_to_jpg.py`
TIF 이미지를 JPG로 변환하는 스크립트

### `new_utils/data_augmentation.py`
데이터 증강을 수행하는 스크립트

## 주요 함수 (utils_merge 폴더)

각 모듈의 역할과 기능은 위의 "utils_merge 모듈 구조" 섹션을 참조하세요.

## 모델 로드

학습된 모델을 로드하려면:

```python
import tensorflow as tf
model = tf.keras.models.load_model('saved_models/FL_2_5_32_8e05_HoldoutPart06.h5')
```

## 참고사항

- **GPU 사용 권장**: 학습 시간을 단축하려면 GPU를 사용하는 것을 권장합니다
- **메모리 관리**: 대용량 데이터셋의 경우 lazy loading 방식을 사용하여 메모리 사용량을 최적화합니다
- **데이터 불균형**: 각 클라이언트의 타일 개수가 다를 수 있으며, 이는 이미지 크기 차이 때문입니다. 연합 학습에서는 가중 평균을 사용하여 자동으로 처리됩니다

## 문제 해결

### GPU가 감지되지 않는 경우
- CUDA와 cuDNN이 올바르게 설치되어 있는지 확인하세요
- TensorFlow GPU 버전이 설치되어 있는지 확인하세요: `pip install tensorflow-gpu`

### 메모리 부족 오류
- 배치 크기를 줄이세요 (`LOCAL_BATCH_SIZE`)
- `remove_large_images.py`를 실행하여 대용량 이미지를 제거하세요

## 라이선스 및 인용

원본 데이터는 Oak Ridge National Laboratory에서 수집 및 컴파일되었으며, [여기](https://www.osti.gov/dataexplorer/biblio/dataset/1779073)에서 사용 가능합니다.

이 데이터를 사용하는 경우 적절히 인용해주세요:
- Dataset: doi:10.13139/ORNLNCCS/1779073
- Related work: [링크](https://www.sciencedirect.com/science/article/pii/S2214860420308253)
