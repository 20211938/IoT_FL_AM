{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c678e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('GPU not found.') if not torch.cuda.is_available() else print(f'Found GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f09171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 라이브러리 import\n",
    "import torch\n",
    "from utils.cnn.classifier import initialize_cnn_classifier\n",
    "from utils.cnn.dataset_functions import create_cnn_dataset, unwrap_client_data, get_label_mapping\n",
    "from utils.cnn.federated_averaging import federated_averaging\n",
    "from utils.cnn.visualization import plot_training_curves, visualize_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea477a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client1: 85개 파일 (테스트로 14개 추출)\n",
      "client2: 85개 파일 (테스트로 14개 추출)\n",
      "client3: 85개 파일 (테스트로 14개 추출)\n",
      "client4: 85개 파일 (테스트로 14개 추출)\n",
      "client5: 85개 파일 (테스트로 14개 추출)\n",
      "client7: 85개 파일 (테스트로 14개 추출)\n",
      "client8: 85개 파일 (테스트로 14개 추출)\n",
      "\n",
      "client6 (테스트): 98개 파일 (다양한 클라이언트에서 추출)\n",
      "총 학습 데이터: 595개\n",
      "총 테스트 데이터: 98개\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 데이터 경로 및 클라이언트 분배 설정 (수정 버전)\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "data_dir = 'data'\n",
    "imagePath0 = f'{data_dir}/0/'\n",
    "imagePath1 = f'{data_dir}/1/'\n",
    "npyPath = f'{data_dir}/annotations/'\n",
    "\n",
    "# 파일 분배 설정\n",
    "total_files = 693\n",
    "num_clients = 6\n",
    "test_client_id = 6  # 테스트용 클라이언트 ID\n",
    "test_data_ratio = 0.10  # 각 클라이언트에서 추출할 비율 (10%)\n",
    "\n",
    "# 전체 파일 리스트 생성\n",
    "all_files = [f'{i:06d}' for i in range(1, total_files + 1)]\n",
    "random.shuffle(all_files)  # 랜덤 셔플 (선택사항)\n",
    "\n",
    "# client6을 제외한 클라이언트에 데이터 분배\n",
    "train_clients = [f'client{i}' for i in range(1, num_clients + 1) if i != test_client_id]\n",
    "num_train_clients = len(train_clients)\n",
    "files_per_train_client = len(all_files) // num_train_clients\n",
    "\n",
    "clientIdentifierDict = {}\n",
    "test_files = []  # client6에 들어갈 파일들\n",
    "\n",
    "# 각 학습 클라이언트에 데이터 분배 및 테스트 데이터 추출\n",
    "start_idx = 0\n",
    "for i, client_id in enumerate(train_clients):\n",
    "    if i < num_train_clients - 1:\n",
    "        end_idx = start_idx + files_per_train_client\n",
    "    else:\n",
    "        end_idx = len(all_files)\n",
    "    \n",
    "    # 클라이언트에 할당된 파일들\n",
    "    client_files = all_files[start_idx:end_idx]\n",
    "    \n",
    "    # 테스트 데이터 추출 (각 클라이언트에서 일정 비율)\n",
    "    num_test_from_client = int(len(client_files) * test_data_ratio)\n",
    "    test_files_from_client = random.sample(client_files, num_test_from_client)\n",
    "    test_files.extend(test_files_from_client)\n",
    "    \n",
    "    # 남은 파일들을 클라이언트에 할당\n",
    "    train_files = [f for f in client_files if f not in test_files_from_client]\n",
    "    clientIdentifierDict[client_id] = train_files\n",
    "    \n",
    "    print(f'{client_id}: {len(train_files)}개 파일 (테스트로 {num_test_from_client}개 추출)')\n",
    "    start_idx = end_idx\n",
    "\n",
    "# client6에 테스트 파일 할당\n",
    "clientIdentifierDict[f'client{test_client_id}'] = test_files\n",
    "print(f'\\nclient{test_client_id} (테스트): {len(test_files)}개 파일 (다양한 클라이언트에서 추출)')\n",
    "print(f'총 학습 데이터: {sum(len(files) for k, files in clientIdentifierDict.items() if k != f\"client{test_client_id}\")}개')\n",
    "print(f'총 테스트 데이터: {len(test_files)}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502403f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 결함 유형 (0과 1 제외): [np.int8(-1), np.uint8(3), np.uint8(4), np.uint8(5), np.uint8(6), np.uint8(7), np.uint8(8), np.uint8(9), np.uint8(11), np.uint8(14), np.uint8(255)]\n",
      "레이블 매핑: {np.int8(-1): 0, np.uint8(3): 1, np.uint8(4): 2, np.uint8(5): 3, np.uint8(6): 4, np.uint8(7): 5, np.uint8(8): 6, np.uint8(9): 7, np.uint8(11): 8, np.uint8(14): 9, np.uint8(255): 10}\n",
      "총 클래스 수: 11\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 레이블 매핑 생성\n",
    "label_mapping, num_classes = get_label_mapping(data_dir, clientIdentifierDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74657f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결함 유형 확인\n",
    "# from utils.cnn.visual_npy import visualize_defect_types_samples\n",
    "\n",
    "# visualize_defect_types_samples(data_dir, clientIdentifierDict, label_mapping, min_pixels=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40b64b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터셋 생성 중...\n",
      "client1...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 78 (filtered 7 invalid labels)\n",
      "Image Tensor Shape: torch.Size([78, 2, 640, 640])\n",
      "Label Shape: torch.Size([78])\n",
      "Label distribution: Counter({np.int64(6): 33, np.int64(1): 14, np.int64(4): 12, np.int64(3): 8, np.int64(7): 4, np.int64(10): 3, np.int64(5): 2, np.int64(0): 1, np.int64(8): 1})\n",
      "client2...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 80 (filtered 5 invalid labels)\n",
      "Image Tensor Shape: torch.Size([80, 2, 640, 640])\n",
      "Label Shape: torch.Size([80])\n",
      "Label distribution: Counter({np.int64(6): 24, np.int64(4): 20, np.int64(1): 16, np.int64(3): 10, np.int64(5): 4, np.int64(7): 3, np.int64(0): 2, np.int64(10): 1})\n",
      "client3...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 83 (filtered 2 invalid labels)\n",
      "Image Tensor Shape: torch.Size([83, 2, 640, 640])\n",
      "Label Shape: torch.Size([83])\n",
      "Label distribution: Counter({np.int64(6): 27, np.int64(1): 20, np.int64(4): 14, np.int64(3): 10, np.int64(10): 6, np.int64(7): 3, np.int64(8): 2, np.int64(5): 1})\n",
      "client4...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 79 (filtered 6 invalid labels)\n",
      "Image Tensor Shape: torch.Size([79, 2, 640, 640])\n",
      "Label Shape: torch.Size([79])\n",
      "Label distribution: Counter({np.int64(6): 26, np.int64(3): 18, np.int64(1): 11, np.int64(7): 7, np.int64(4): 6, np.int64(10): 5, np.int64(5): 3, np.int64(8): 2, np.int64(0): 1})\n",
      "client5...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 83 (filtered 2 invalid labels)\n",
      "Image Tensor Shape: torch.Size([83, 2, 640, 640])\n",
      "Label Shape: torch.Size([83])\n",
      "Label distribution: Counter({np.int64(6): 32, np.int64(1): 12, np.int64(4): 11, np.int64(3): 9, np.int64(10): 6, np.int64(7): 5, np.int64(0): 3, np.int64(8): 3, np.int64(5): 2})\n",
      "client7...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 82 (filtered 3 invalid labels)\n",
      "Image Tensor Shape: torch.Size([82, 2, 640, 640])\n",
      "Label Shape: torch.Size([82])\n",
      "Label distribution: Counter({np.int64(6): 31, np.int64(3): 14, np.int64(1): 14, np.int64(4): 13, np.int64(10): 3, np.int64(8): 3, np.int64(0): 2, np.int64(7): 2})\n",
      "client8...\n",
      "  처리 중: 50/85 파일 완료\n",
      "Contains 85 images...\n",
      "Valid images: 82 (filtered 3 invalid labels)\n",
      "Image Tensor Shape: torch.Size([82, 2, 640, 640])\n",
      "Label Shape: torch.Size([82])\n",
      "Label distribution: Counter({np.int64(6): 26, np.int64(4): 17, np.int64(1): 12, np.int64(3): 10, np.int64(10): 6, np.int64(7): 4, np.int64(5): 3, np.int64(8): 2, np.int64(0): 2})\n",
      "client6...\n",
      "  처리 중: 50/98 파일 완료\n",
      "Contains 98 images...\n",
      "Valid images: 94 (filtered 4 invalid labels)\n",
      "Image Tensor Shape: torch.Size([94, 2, 640, 640])\n",
      "Label Shape: torch.Size([94])\n",
      "Label distribution: Counter({np.int64(6): 29, np.int64(4): 19, np.int64(3): 17, np.int64(1): 13, np.int64(10): 6, np.int64(7): 4, np.int64(8): 4, np.int64(5): 1, np.int64(0): 1})\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 데이터셋 생성\n",
    "target_size = (640, 640)\n",
    "print(\"\\n데이터셋 생성 중...\")\n",
    "imageDict, labelDict = create_cnn_dataset(\n",
    "    clientIdentifierDict,\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    label_mapping=label_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e6b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train/Test 분할\n",
    "trainClients = ['client1', 'client2', 'client3', 'client4', \n",
    "                'client5', 'client7', 'client8']\n",
    "testClients = ['client6']\n",
    "\n",
    "clientIDs = trainClients\n",
    "\n",
    "# Train Data\n",
    "trainImageDict = {clientID: imageDict[clientID] for clientID in trainClients}\n",
    "trainLabelDict = {clientID: labelDict[clientID] for clientID in trainClients}\n",
    "\n",
    "# Test Data\n",
    "testImageDict = {clientID: imageDict[clientID] for clientID in testClients}\n",
    "testLabelDict = {clientID: labelDict[clientID] for clientID in testClients}\n",
    "\n",
    "testImages, testLabels = unwrap_client_data(testImageDict, testLabelDict, testClients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a9cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 레이블 검증\n",
    "# print(\"\\n레이블 범위 검증:\")\n",
    "# for clientID in clientIDs:\n",
    "#     labels = trainLabelDict[clientID]\n",
    "#     min_label = labels.min().item()\n",
    "#     max_label = labels.max().item()\n",
    "#     invalid_count = ((labels < 0) | (labels >= num_classes)).sum().item()\n",
    "#     print(f\"{clientID}: min={min_label}, max={max_label}, invalid={invalid_count}\")\n",
    "#     if invalid_count > 0:\n",
    "#         print(f\"  경고: {clientID}에 유효하지 않은 레이블이 {invalid_count}개 있습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132f8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 하이퍼파라미터 설정\n",
    "SERVER_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 15\n",
    "LOCAL_BATCH_SIZE = 32\n",
    "LOCAL_LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e392416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 초기화 완료! 클래스 수: 11\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: 모델 초기화\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = initialize_cnn_classifier(num_classes, input_channels=2, device=device)\n",
    "print(f\"모델 초기화 완료! 클래스 수: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "597c7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "------ Server Round 0 ------\n",
      "============================================================\n",
      "\n",
      "Running local updates for client1...\n",
      "Epoch 1/15 - Loss: 2.3337, Accuracy: 30.77%\n",
      "Epoch 2/15 - Loss: 2.1278, Accuracy: 64.10%\n",
      "Epoch 3/15 - Loss: 1.9177, Accuracy: 65.38%\n",
      "Epoch 4/15 - Loss: 1.7672, Accuracy: 75.64%\n",
      "Epoch 5/15 - Loss: 1.5873, Accuracy: 70.51%\n",
      "Epoch 6/15 - Loss: 1.3972, Accuracy: 75.64%\n",
      "Epoch 7/15 - Loss: 1.2842, Accuracy: 69.23%\n",
      "Epoch 8/15 - Loss: 1.4208, Accuracy: 66.67%\n",
      "Epoch 9/15 - Loss: 1.3047, Accuracy: 74.36%\n",
      "Epoch 10/15 - Loss: 0.9493, Accuracy: 79.49%\n",
      "Epoch 11/15 - Loss: 1.0354, Accuracy: 74.36%\n",
      "Epoch 12/15 - Loss: 0.8518, Accuracy: 74.36%\n",
      "Epoch 13/15 - Loss: 0.8583, Accuracy: 78.21%\n",
      "Epoch 14/15 - Loss: 0.8505, Accuracy: 85.90%\n",
      "Epoch 15/15 - Loss: 0.7618, Accuracy: 82.05%\n",
      "Saving local updates for client1...\n",
      "\n",
      "Running local updates for client2...\n",
      "Epoch 1/15 - Loss: 2.3425, Accuracy: 22.50%\n",
      "Epoch 2/15 - Loss: 2.2254, Accuracy: 43.75%\n",
      "Epoch 3/15 - Loss: 1.9699, Accuracy: 65.00%\n",
      "Epoch 4/15 - Loss: 1.8732, Accuracy: 71.25%\n",
      "Epoch 5/15 - Loss: 1.6757, Accuracy: 71.25%\n",
      "Epoch 6/15 - Loss: 1.5925, Accuracy: 63.75%\n",
      "Epoch 7/15 - Loss: 1.4571, Accuracy: 66.25%\n",
      "Epoch 8/15 - Loss: 1.3286, Accuracy: 68.75%\n",
      "Epoch 9/15 - Loss: 1.2052, Accuracy: 70.00%\n",
      "Epoch 10/15 - Loss: 1.1695, Accuracy: 68.75%\n",
      "Epoch 11/15 - Loss: 1.0684, Accuracy: 68.75%\n",
      "Epoch 12/15 - Loss: 0.9582, Accuracy: 75.00%\n",
      "Epoch 13/15 - Loss: 0.9554, Accuracy: 75.00%\n",
      "Epoch 14/15 - Loss: 0.9312, Accuracy: 72.50%\n",
      "Epoch 15/15 - Loss: 0.9215, Accuracy: 71.25%\n",
      "Saving local updates for client2...\n",
      "\n",
      "Running local updates for client3...\n",
      "Epoch 1/15 - Loss: 2.3654, Accuracy: 14.46%\n",
      "Epoch 2/15 - Loss: 2.1271, Accuracy: 66.27%\n",
      "Epoch 3/15 - Loss: 1.9555, Accuracy: 63.86%\n",
      "Epoch 4/15 - Loss: 1.7907, Accuracy: 73.49%\n",
      "Epoch 5/15 - Loss: 1.6042, Accuracy: 79.52%\n",
      "Epoch 6/15 - Loss: 1.4927, Accuracy: 79.52%\n",
      "Epoch 7/15 - Loss: 1.3808, Accuracy: 80.72%\n",
      "Epoch 8/15 - Loss: 1.3011, Accuracy: 78.31%\n",
      "Epoch 9/15 - Loss: 1.1393, Accuracy: 84.34%\n",
      "Epoch 10/15 - Loss: 1.0102, Accuracy: 84.34%\n",
      "Epoch 11/15 - Loss: 0.9308, Accuracy: 85.54%\n",
      "Epoch 12/15 - Loss: 0.8961, Accuracy: 84.34%\n",
      "Epoch 13/15 - Loss: 0.7893, Accuracy: 83.13%\n",
      "Epoch 14/15 - Loss: 0.7658, Accuracy: 84.34%\n",
      "Epoch 15/15 - Loss: 0.8016, Accuracy: 80.72%\n",
      "Saving local updates for client3...\n",
      "\n",
      "Running local updates for client4...\n",
      "Epoch 1/15 - Loss: 2.3519, Accuracy: 25.32%\n",
      "Epoch 2/15 - Loss: 2.1558, Accuracy: 55.70%\n",
      "Epoch 3/15 - Loss: 1.9586, Accuracy: 63.29%\n",
      "Epoch 4/15 - Loss: 1.8360, Accuracy: 65.82%\n",
      "Epoch 5/15 - Loss: 1.6000, Accuracy: 69.62%\n",
      "Epoch 6/15 - Loss: 1.4276, Accuracy: 75.95%\n",
      "Epoch 7/15 - Loss: 1.3286, Accuracy: 70.89%\n",
      "Epoch 8/15 - Loss: 1.3229, Accuracy: 70.89%\n",
      "Epoch 9/15 - Loss: 1.3245, Accuracy: 73.42%\n",
      "Epoch 10/15 - Loss: 1.0651, Accuracy: 69.62%\n",
      "Epoch 11/15 - Loss: 1.0195, Accuracy: 68.35%\n",
      "Epoch 12/15 - Loss: 0.9190, Accuracy: 72.15%\n",
      "Epoch 13/15 - Loss: 0.9014, Accuracy: 68.35%\n",
      "Epoch 14/15 - Loss: 0.8103, Accuracy: 79.75%\n",
      "Epoch 15/15 - Loss: 0.9097, Accuracy: 69.62%\n",
      "Saving local updates for client4...\n",
      "\n",
      "Running local updates for client5...\n",
      "Epoch 1/15 - Loss: 2.3524, Accuracy: 21.69%\n",
      "Epoch 2/15 - Loss: 2.1723, Accuracy: 59.04%\n",
      "Epoch 3/15 - Loss: 1.9979, Accuracy: 59.04%\n",
      "Epoch 4/15 - Loss: 1.8923, Accuracy: 62.65%\n",
      "Epoch 5/15 - Loss: 1.6850, Accuracy: 72.29%\n",
      "Epoch 6/15 - Loss: 1.4650, Accuracy: 67.47%\n",
      "Epoch 7/15 - Loss: 1.3695, Accuracy: 67.47%\n",
      "Epoch 8/15 - Loss: 1.2426, Accuracy: 74.70%\n",
      "Epoch 9/15 - Loss: 1.2089, Accuracy: 68.67%\n",
      "Epoch 10/15 - Loss: 1.2278, Accuracy: 72.29%\n",
      "Epoch 11/15 - Loss: 1.0862, Accuracy: 71.08%\n",
      "Epoch 12/15 - Loss: 1.0358, Accuracy: 73.49%\n",
      "Epoch 13/15 - Loss: 0.9849, Accuracy: 72.29%\n",
      "Epoch 14/15 - Loss: 0.9498, Accuracy: 73.49%\n",
      "Epoch 15/15 - Loss: 0.9048, Accuracy: 74.70%\n",
      "Saving local updates for client5...\n",
      "\n",
      "Running local updates for client7...\n",
      "Epoch 1/15 - Loss: 2.3427, Accuracy: 23.17%\n",
      "Epoch 2/15 - Loss: 2.1467, Accuracy: 64.63%\n",
      "Epoch 3/15 - Loss: 1.9265, Accuracy: 76.83%\n",
      "Epoch 4/15 - Loss: 1.6907, Accuracy: 75.61%\n",
      "Epoch 5/15 - Loss: 1.6405, Accuracy: 73.17%\n",
      "Epoch 6/15 - Loss: 1.4571, Accuracy: 71.95%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 8: 연합학습 실행\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model, serverStateDict, lossDict, testLoss, accuracyDict, testAccuracy = \u001b[43mfederated_averaging\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSERVER_ROUNDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCAL_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCAL_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCAL_LEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclientIDs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainImageDict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLabelDict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestLabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\iot\\IoT_FL_AM\\utils\\cnn\\federated_averaging.py:127\u001b[39m, in \u001b[36mfederated_averaging\u001b[39m\u001b[34m(model, SERVER_ROUNDS, LOCAL_EPOCHS, LOCAL_BATCH_SIZE, LOCAL_LEARNING_RATE, clientIDs, imageDict, labelDict, testImages, testLabels, num_classes, device)\u001b[39m\n\u001b[32m    124\u001b[39m optimizer.step()\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# 통계\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m epoch_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m _, predicted = torch.max(outputs.data, \u001b[32m1\u001b[39m)\n\u001b[32m    129\u001b[39m total += batch_labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 8: 연합학습 실행\n",
    "model, serverStateDict, lossDict, testLoss, accuracyDict, testAccuracy = federated_averaging(\n",
    "    model,\n",
    "    SERVER_ROUNDS, LOCAL_EPOCHS, LOCAL_BATCH_SIZE, LOCAL_LEARNING_RATE,\n",
    "    clientIDs, trainImageDict, trainLabelDict,\n",
    "    testImages, testLabels,\n",
    "    num_classes,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d456d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: 학습 곡선 시각화\n",
    "plot_training_curves(lossDict, accuracyDict, testLoss, testAccuracy, clientIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: 모델 저장\n",
    "import os\n",
    "from utils.cnn.classifier import save_cnn_model\n",
    "\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "test_set_name = ''.join([c.replace('client', '') for c in testClients])\n",
    "if len(test_set_name) == 1:\n",
    "    test_set_name = '0' + test_set_name\n",
    "\n",
    "lr_str = f\"{LOCAL_LEARNING_RATE:.0e}\".replace('-', '').replace('+', '').replace('.0', '')\n",
    "base_filename = f'saved_models/CNN_FL_{SERVER_ROUNDS}_{LOCAL_EPOCHS}_{LOCAL_BATCH_SIZE}_{lr_str}_HoldoutPart{test_set_name}.pth'\n",
    "\n",
    "model_filename = base_filename\n",
    "counter = 1\n",
    "while os.path.exists(model_filename):\n",
    "    base_name, ext = os.path.splitext(base_filename)\n",
    "    model_filename = f'{base_name}_{counter}{ext}'\n",
    "    counter += 1\n",
    "\n",
    "save_cnn_model(model, model_filename, num_classes=num_classes)\n",
    "print(f'\\n최종 테스트 성능:')\n",
    "print(f'  Loss: {testLoss[-1]:.4f}')\n",
    "print(f'  Accuracy: {testAccuracy[-1]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c919f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: 예측 결과 시각화\n",
    "visualize_predictions(\n",
    "    model, testImageDict, testLabelDict, testClients,\n",
    "    clientIdentifierDict, data_dir, num_samples=6, device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
