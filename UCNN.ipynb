{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67208051",
   "metadata": {},
   "source": [
    "# 학습된 모델 테스트 및 평가 파이프라인\n",
    "\n",
    "이 노트북은 학습 완료된 두 모델을 사용하여 실제 데이터로 테스트합니다:\n",
    "- **U-Net 모델** (Federated_learning_merged_data.ipynb에서 학습): 결함 검출\n",
    "- **CNN 모델** (CNN_Federated_Learning.ipynb에서 학습): 결함 유형 분류\n",
    "\n",
    "## 진행 순서\n",
    "1. **환경 설정**: GPU 확인 및 라이브러리 import\n",
    "2. **모델 로드**: U-Net과 CNN 모델 로드\n",
    "3. **데이터 준비**: 테스트 데이터 준비 및 레이블 매핑 생성\n",
    "4. **U-Net 테스트**: 결함 검출 성능 평가\n",
    "5. **CNN 테스트**: 결함 유형 분류 성능 평가\n",
    "6. **결과 시각화**: 검출 및 분류 결과 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188d5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow GPU: GPU not found.\n",
      "PyTorch GPU: Found GPU: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "# GPU 확인\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow GPU 확인\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print('TensorFlow GPU:', 'Found GPU at: {}'.format(device_name) if device_name == '/device:GPU:0' else 'GPU not found.')\n",
    "\n",
    "# PyTorch GPU 확인\n",
    "print('PyTorch GPU:', f'Found GPU: {torch.cuda.get_device_name(0)}' if torch.cuda.is_available() else 'GPU not found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f855fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# 유틸리티 함수 import\n",
    "from utils.cnn.defect_detection import scan_data_directory, load_image_for_cnn, get_defect_type_from_npy\n",
    "from utils.cnn.classifier import load_cnn_model\n",
    "from utils.cnn.dataset_functions import get_label_mapping, create_cnn_dataset, unwrap_client_data\n",
    "from utils.u_net.dataset_functions import create_dataset, unwrap_client_data as unwrap_unet_data\n",
    "from utils.u_net.image_processing import unsplit_image_mask\n",
    "\n",
    "print(\"라이브러리 import 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a059f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 디렉터리: data\n",
      "U-Net 모델 경로: saved_models/FL_2_5_32_8e05_HoldoutPart06_1.h5\n",
      "CNN 모델 경로: saved_models/CNN_FL_1_1_32_1e04_HoldoutPart06.pth\n",
      "최대 파일 개수: 전체\n"
     ]
    }
   ],
   "source": [
    "# 경로 설정\n",
    "data_dir = 'data'  # data 폴더 경로\n",
    "unet_model_path = 'saved_models/FL_2_5_32_8e05_HoldoutPart06_1.h5'  # U-Net 모델 경로\n",
    "cnn_model_path = 'saved_models/CNN_FL_1_1_32_1e04_HoldoutPart06.pth'  # CNN 모델 경로\n",
    "\n",
    "# 테스트 데이터 설정\n",
    "max_files = None  # None이면 전체 사용, 숫자를 지정하면 해당 개수만 사용\n",
    "test_data_ratio = 0.15  # 전체 데이터에서 테스트 데이터 비율\n",
    "\n",
    "print(f\"Data 디렉터리: {data_dir}\")\n",
    "print(f\"U-Net 모델 경로: {unet_model_path}\")\n",
    "print(f\"CNN 모델 경로: {cnn_model_path}\")\n",
    "print(f\"최대 파일 개수: {max_files if max_files else '전체'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e6efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1단계: 학습된 모델 로드\n",
      "============================================================\n",
      "\n",
      "[1-1] U-Net 모델 로드 중...\n",
      "✓ U-Net 모델 로드 완료!\n",
      "  입력 shape: (None, 128, 128, 2)\n",
      "  출력 shape: (None, 128, 128, 3)\n",
      "\n",
      "[1-2] CNN 모델 로드 중...\n",
      "✓ CNN 모델 로드 완료!\n",
      "  Device: cuda\n",
      "  모델 파라미터 수: 5,110,731\n"
     ]
    }
   ],
   "source": [
    "## 1단계: 모델 로드\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"1단계: 학습된 모델 로드\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# U-Net 모델 로드 (TensorFlow)\n",
    "print(\"\\n[1-1] U-Net 모델 로드 중...\")\n",
    "unet_model = tf.keras.models.load_model(unet_model_path, compile=False)\n",
    "print(\"✓ U-Net 모델 로드 완료!\")\n",
    "print(f\"  입력 shape: {unet_model.input_shape}\")\n",
    "print(f\"  출력 shape: {unet_model.output_shape}\")\n",
    "\n",
    "# CNN 모델 로드 (PyTorch)\n",
    "print(\"\\n[1-2] CNN 모델 로드 중...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn_model = load_cnn_model(cnn_model_path, device=device)\n",
    "print(\"✓ CNN 모델 로드 완료!\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  모델 파라미터 수: {sum(p.numel() for p in cnn_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf23509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2단계: 테스트 데이터 준비\n",
      "============================================================\n",
      "\n",
      "[2-1] 데이터 디렉터리 스캔 중...\n",
      "✓ 총 693개의 파일 발견\n",
      "\n",
      "✓ 클라이언트 분배 완료:\n",
      "  client1 (학습): 85개 파일\n",
      "  client2 (학습): 85개 파일\n",
      "  client3 (학습): 85개 파일\n",
      "  client4 (학습): 85개 파일\n",
      "  client5 (학습): 85개 파일\n",
      "  client7 (학습): 85개 파일\n",
      "  client8 (학습): 85개 파일\n",
      "  client6 (테스트): 98개 파일\n",
      "\n",
      "[2-2] 레이블 매핑 생성 중...\n",
      "발견된 결함 유형 (0과 1 제외): [np.int8(-1), np.uint8(3), np.uint8(4), np.uint8(5), np.uint8(6), np.int8(7), np.uint8(8), np.uint8(9), np.int8(11), np.uint8(14), np.uint8(255)]\n",
      "레이블 매핑: {np.int8(-1): 0, np.uint8(3): 1, np.uint8(4): 2, np.uint8(5): 3, np.uint8(6): 4, np.int8(7): 5, np.uint8(8): 6, np.uint8(9): 7, np.int8(11): 8, np.uint8(14): 9, np.uint8(255): 10}\n",
      "총 클래스 수: 11\n",
      "✓ 레이블 매핑 완료: 11개 클래스\n"
     ]
    }
   ],
   "source": [
    "## 2단계: 데이터 준비 및 레이블 매핑 생성\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2단계: 테스트 데이터 준비\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 데이터 디렉터리 스캔\n",
    "print(\"\\n[2-1] 데이터 디렉터리 스캔 중...\")\n",
    "file_list = scan_data_directory(data_dir)\n",
    "print(f\"✓ 총 {len(file_list)}개의 파일 발견\")\n",
    "\n",
    "# 데이터 개수 제한 적용\n",
    "if max_files is not None and max_files > 0:\n",
    "    file_list = file_list[:max_files]\n",
    "    print(f\"✓ 데이터 개수 제한: {len(file_list)}개 파일 사용\")\n",
    "\n",
    "# 테스트 데이터 분할 (CNN 모델 학습 시와 동일한 방식)\n",
    "import random\n",
    "\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "test_client_id = 6\n",
    "num_clients = 8\n",
    "train_clients = [f'client{i}' for i in range(1, num_clients + 1) if i != test_client_id]\n",
    "\n",
    "# 전체 파일을 클라이언트에 분배 (CNN 학습 시와 동일한 방식)\n",
    "random.shuffle(file_list)\n",
    "files_per_client = len(file_list) // len(train_clients)\n",
    "\n",
    "clientIdentifierDict = {}\n",
    "test_files = []\n",
    "\n",
    "start_idx = 0\n",
    "for i, client_id in enumerate(train_clients):\n",
    "    if i < len(train_clients) - 1:\n",
    "        end_idx = start_idx + files_per_client\n",
    "    else:\n",
    "        end_idx = len(file_list)\n",
    "    \n",
    "    client_files = file_list[start_idx:end_idx]\n",
    "    \n",
    "    # 테스트 데이터 추출\n",
    "    num_test_from_client = int(len(client_files) * test_data_ratio)\n",
    "    test_files_from_client = random.sample(client_files, num_test_from_client)\n",
    "    test_files.extend(test_files_from_client)\n",
    "    \n",
    "    # 학습 데이터\n",
    "    train_files = [f for f in client_files if f not in test_files_from_client]\n",
    "    clientIdentifierDict[client_id] = train_files\n",
    "    \n",
    "    start_idx = end_idx\n",
    "\n",
    "# 테스트 클라이언트 설정\n",
    "clientIdentifierDict[f'client{test_client_id}'] = test_files\n",
    "\n",
    "print(f\"\\n✓ 클라이언트 분배 완료:\")\n",
    "for client_id, files in clientIdentifierDict.items():\n",
    "    if client_id == f'client{test_client_id}':\n",
    "        print(f\"  {client_id} (테스트): {len(files)}개 파일\")\n",
    "    else:\n",
    "        print(f\"  {client_id} (학습): {len(files)}개 파일\")\n",
    "\n",
    "# 레이블 매핑 생성 (CNN 모델과 동일한 매핑 필요)\n",
    "print(\"\\n[2-2] 레이블 매핑 생성 중...\")\n",
    "label_mapping, num_classes = get_label_mapping(data_dir, clientIdentifierDict)\n",
    "print(f\"✓ 레이블 매핑 완료: {num_classes}개 클래스\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc7d54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3단계: U-Net 결함 검출 테스트\n",
      "============================================================\n",
      "\n",
      "[3-1] U-Net 테스트 데이터셋 생성 중...\n",
      "\n",
      "test...\n",
      "  처리 중: 50/98 파일 완료 (현재 타일 수: 3050)\n",
      "  처리 중: 98/98 파일 완료 (현재 타일 수: 5250)\n",
      "Contains 98 images...\n",
      "Tiled Image Tensor Shape:  (5250, 128, 128, 2)\n",
      "Tiled Mask Shape:  (5250, 128, 128)\n",
      "✓ 데이터셋 생성 완료\n",
      "\n",
      "[3-2] U-Net 예측 수행 중...\n",
      "총 5250개 타일 예측 중...\n",
      "\n",
      "✓ U-Net 검출 완료!\n",
      "\n",
      "[검출 성능]\n",
      "  정확도 (Accuracy): 0.3061\n",
      "  정밀도 (Precision): 0.9565\n",
      "  재현율 (Recall): 0.2472\n",
      "  F1 점수: 0.3929\n",
      "\n",
      "[검출 결과]\n",
      "  True Positives: 22\n",
      "  False Positives: 1\n",
      "  False Negatives: 67\n",
      "  True Negatives: 8\n",
      "  총 테스트 파일: 98개\n"
     ]
    }
   ],
   "source": [
    "## 3단계: U-Net 모델 테스트 - 결함 검출 성능 평가\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3단계: U-Net 결함 검출 테스트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# U-Net용 데이터셋 생성\n",
    "tileSize = 128\n",
    "defect_threshold = 0.01\n",
    "\n",
    "test_client_id = 6\n",
    "test_clients = [f'client{test_client_id}']\n",
    "test_files = clientIdentifierDict[f'client{test_client_id}']\n",
    "\n",
    "# 테스트 파일 그룹 생성\n",
    "test_file_groups = {'test': test_files}\n",
    "\n",
    "imagePath0 = f'{data_dir}/0/'\n",
    "imagePath1 = f'{data_dir}/1/'\n",
    "npyPath = f'{data_dir}/annotations/'\n",
    "\n",
    "print(\"\\n[3-1] U-Net 테스트 데이터셋 생성 중...\")\n",
    "testImageDict, testMaskDict = create_dataset(\n",
    "    test_file_groups,\n",
    "    imagePath0,\n",
    "    imagePath1,\n",
    "    npyPath,\n",
    "    tileSize=tileSize\n",
    ")\n",
    "print(\"✓ 데이터셋 생성 완료\")\n",
    "\n",
    "# U-Net 예측 수행\n",
    "print(\"\\n[3-2] U-Net 예측 수행 중...\")\n",
    "testImages, testMasks = unwrap_unet_data(testImageDict, testMaskDict, ['test'])\n",
    "print(f\"총 {testImages.shape[0]}개 타일 예측 중...\")\n",
    "\n",
    "predictedImages = unet_model.predict(testImages, verbose=0)\n",
    "predictedMask = tf.argmax(predictedImages, axis=-1)\n",
    "\n",
    "# 각 이미지별로 결과 수집\n",
    "unet_results = []\n",
    "num_tiles_per_image = 25  # 640x640 = 5*5 = 25 타일\n",
    "curr_idx = 0\n",
    "\n",
    "for file_name in test_files:\n",
    "    prev_idx = curr_idx\n",
    "    curr_idx = prev_idx + num_tiles_per_image\n",
    "    \n",
    "    # 타일 재구성\n",
    "    imageheight, imagewidth = 5*128, 5*128  # 640x640\n",
    "    fullPredictedMask = unsplit_image_mask(\n",
    "        predictedMask[prev_idx:curr_idx],\n",
    "        imageheight,\n",
    "        imagewidth\n",
    "    )\n",
    "    \n",
    "    # 결함 검출\n",
    "    defect_mask = fullPredictedMask[0, :, :, 0].numpy()\n",
    "    defect_ratio = np.sum(defect_mask == 2) / defect_mask.size if defect_mask.size > 0 else 0.0\n",
    "    has_defect = defect_ratio > defect_threshold\n",
    "    \n",
    "    # 실제 레이블 확인\n",
    "    npy_path = Path(npyPath) / f\"{file_name}.npy\"\n",
    "    actual_defect_type, _ = get_defect_type_from_npy(str(npy_path))\n",
    "    actual_has_defect = actual_defect_type is not None\n",
    "    \n",
    "    unet_results.append({\n",
    "        'file_name': file_name,\n",
    "        'predicted_has_defect': has_defect,\n",
    "        'actual_has_defect': actual_has_defect,\n",
    "        'defect_ratio': defect_ratio,\n",
    "        'mask': defect_mask\n",
    "    })\n",
    "    \n",
    "    if curr_idx >= len(predictedMask):\n",
    "        break\n",
    "\n",
    "# 성능 평가\n",
    "true_positives = sum(1 for r in unet_results if r['predicted_has_defect'] and r['actual_has_defect'])\n",
    "false_positives = sum(1 for r in unet_results if r['predicted_has_defect'] and not r['actual_has_defect'])\n",
    "false_negatives = sum(1 for r in unet_results if not r['predicted_has_defect'] and r['actual_has_defect'])\n",
    "true_negatives = sum(1 for r in unet_results if not r['predicted_has_defect'] and not r['actual_has_defect'])\n",
    "\n",
    "unet_precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "unet_recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "unet_f1_score = 2 * (unet_precision * unet_recall) / (unet_precision + unet_recall) if (unet_precision + unet_recall) > 0 else 0\n",
    "unet_accuracy = (true_positives + true_negatives) / len(unet_results) if len(unet_results) > 0 else 0\n",
    "\n",
    "print(f\"\\n✓ U-Net 검출 완료!\")\n",
    "print(f\"\\n[검출 성능]\")\n",
    "print(f\"  정확도 (Accuracy): {unet_accuracy:.4f}\")\n",
    "print(f\"  정밀도 (Precision): {unet_precision:.4f}\")\n",
    "print(f\"  재현율 (Recall): {unet_recall:.4f}\")\n",
    "print(f\"  F1 점수: {unet_f1_score:.4f}\")\n",
    "print(f\"\\n[검출 결과]\")\n",
    "print(f\"  True Positives: {true_positives}\")\n",
    "print(f\"  False Positives: {false_positives}\")\n",
    "print(f\"  False Negatives: {false_negatives}\")\n",
    "print(f\"  True Negatives: {true_negatives}\")\n",
    "print(f\"  총 테스트 파일: {len(unet_results)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4단계: CNN 결함 유형 분류 테스트\n",
      "============================================================\n",
      "\n",
      "[4-1] CNN 테스트 데이터셋 생성 중...\n",
      "client6...\n",
      "Contains 98 images...\n",
      "Valid images: 89 (filtered 9 invalid labels)\n",
      "Image Tensor Shape: torch.Size([89, 2, 640, 640])\n",
      "Label Shape: torch.Size([89])\n",
      "Label distribution: Counter({np.int64(6): 32, np.int64(4): 16, np.int64(3): 13, np.int64(1): 12, np.int64(10): 5, np.int64(8): 4, np.int64(5): 3, np.int64(7): 3, np.int64(0): 1})\n",
      "✓ 데이터셋 생성 완료\n",
      "테스트 이미지 shape: torch.Size([89, 2, 640, 640])\n",
      "테스트 레이블 shape: torch.Size([89])\n",
      "\n",
      "[4-2] CNN 예측 수행 중...\n",
      "\n",
      "✓ CNN 분류 완료!\n",
      "\n",
      "[분류 성능]\n",
      "  정확도 (Accuracy): 0.0562 (5/89)\n",
      "\n",
      "[상세 분류 리포트]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 9, does not match size of target_names, 11. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 상세 성능 리포트\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[상세 분류 리포트]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mClass_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Confusion Matrix 생성\u001b[39;00m\n\u001b[32m     60\u001b[39m cm = confusion_matrix(test_labels_np, predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\iot\\IoT_FL_AM\\venv311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\iot\\IoT_FL_AM\\venv311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2970\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2964\u001b[39m         warnings.warn(\n\u001b[32m   2965\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2966\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[32m   2967\u001b[39m             )\n\u001b[32m   2968\u001b[39m         )\n\u001b[32m   2969\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2970\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2971\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2972\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m. Try specifying the labels \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2973\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[32m   2974\u001b[39m         )\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2976\u001b[39m     target_names = [\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[31mValueError\u001b[39m: Number of classes, 9, does not match size of target_names, 11. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "## 4단계: CNN 모델 테스트 - 결함 유형 분류 성능 평가\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4단계: CNN 결함 유형 분류 테스트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CNN용 테스트 데이터셋 생성\n",
    "print(\"\\n[4-1] CNN 테스트 데이터셋 생성 중...\")\n",
    "target_size = (640, 640)\n",
    "testImageDict, testLabelDict = create_cnn_dataset(\n",
    "    {f'client{test_client_id}': test_files},\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    label_mapping=label_mapping\n",
    ")\n",
    "print(\"✓ 데이터셋 생성 완료\")\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "testImages, testLabels = unwrap_client_data(testImageDict, testLabelDict, [f'client{test_client_id}'])\n",
    "testImages = testImages.to(device)\n",
    "\n",
    "print(f\"테스트 이미지 shape: {testImages.shape}\")\n",
    "print(f\"테스트 레이블 shape: {testLabels.shape}\")\n",
    "\n",
    "# CNN 예측 수행\n",
    "print(\"\\n[4-2] CNN 예측 수행 중...\")\n",
    "batch_size = 32\n",
    "predictions = []\n",
    "probabilities_list = []\n",
    "\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(testImages), batch_size):\n",
    "        batch_images = testImages[i:i+batch_size]\n",
    "        outputs = cnn_model(batch_images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        probabilities_list.extend(probs.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "probabilities_list = np.array(probabilities_list)\n",
    "test_labels_np = testLabels.numpy()\n",
    "\n",
    "# 성능 평가\n",
    "correct = (predictions == test_labels_np).sum()\n",
    "cnn_accuracy = correct / len(test_labels_np)\n",
    "\n",
    "print(f\"\\n✓ CNN 분류 완료!\")\n",
    "print(f\"\\n[분류 성능]\")\n",
    "print(f\"  정확도 (Accuracy): {cnn_accuracy:.4f} ({correct}/{len(test_labels_np)})\")\n",
    "\n",
    "# 실제로 존재하는 클래스만 추출\n",
    "unique_labels = np.unique(np.concatenate([test_labels_np, predictions]))\n",
    "unique_labels = np.sort(unique_labels)\n",
    "print(f\"\\n  테스트 데이터에 존재하는 클래스: {unique_labels.tolist()}\")\n",
    "print(f\"  총 클래스 수: {len(unique_labels)}개 (전체 {num_classes}개 중)\")\n",
    "\n",
    "# 상세 성능 리포트 (실제 존재하는 클래스만 사용)\n",
    "print(f\"\\n[상세 분류 리포트]\")\n",
    "target_names = [f'Class_{i}' for i in unique_labels]\n",
    "print(classification_report(test_labels_np, predictions, \n",
    "                          labels=unique_labels,\n",
    "                          target_names=target_names,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Confusion Matrix 생성 (실제 존재하는 클래스만 사용)\n",
    "cm = confusion_matrix(test_labels_np, predictions, labels=unique_labels)\n",
    "print(f\"\\n[Confusion Matrix]\")\n",
    "print(f\"클래스: {unique_labels.tolist()}\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5단계: 결과 시각화\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5단계: 결과 시각화\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# unique_labels가 정의되지 않은 경우를 대비 (Cell 7을 먼저 실행해야 함)\n",
    "if 'unique_labels' not in locals():\n",
    "    # 실제로 존재하는 클래스만 추출\n",
    "    unique_labels = np.unique(np.concatenate([test_labels_np, predictions]))\n",
    "    unique_labels = np.sort(unique_labels)\n",
    "    print(f\"\\n  참고: 테스트 데이터에 존재하는 클래스: {unique_labels.tolist()}\")\n",
    "\n",
    "# 5-1: U-Net 검출 결과 시각화\n",
    "print(\"\\n[5-1] U-Net 검출 결과 시각화\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 결함이 검출된 이미지 몇 개 선택\n",
    "defect_detected = [r for r in unet_results if r['predicted_has_defect']]\n",
    "sample_results = defect_detected[:6] if len(defect_detected) >= 6 else defect_detected\n",
    "\n",
    "for idx, result in enumerate(sample_results):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "    \n",
    "    file_name = result['file_name']\n",
    "    img0_path = Path(imagePath0) / f\"{file_name}.jpg\"\n",
    "    img1_path = Path(imagePath1) / f\"{file_name}.jpg\"\n",
    "    \n",
    "    # 원본 이미지 로드 (Post Fusion)\n",
    "    img = plt.imread(str(img1_path))\n",
    "    axes[idx].imshow(img, cmap='gray')\n",
    "    axes[idx].set_title(f\"{file_name}\\n결함 비율: {result['defect_ratio']:.3f}\\n\"\n",
    "                       f\"예측: {'결함' if result['predicted_has_defect'] else '정상'}\\n\"\n",
    "                       f\"실제: {'결함' if result['actual_has_defect'] else '정상'}\",\n",
    "                       fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# 빈 subplot 제거\n",
    "for idx in range(len(sample_results), 6):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('U-Net 결함 검출 결과 (샘플)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-2: CNN 분류 Confusion Matrix 시각화\n",
    "print(\"\\n[5-2] CNN 분류 Confusion Matrix 시각화\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[f'Class_{i}' for i in unique_labels],\n",
    "            yticklabels=[f'Class_{i}' for i in unique_labels])\n",
    "plt.title('CNN 결함 유형 분류 Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('예측 레이블')\n",
    "plt.ylabel('실제 레이블')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-3: 클래스별 정확도 (실제 존재하는 클래스만)\n",
    "print(\"\\n[5-3] 클래스별 분류 정확도\")\n",
    "\n",
    "class_accuracies = []\n",
    "for i in unique_labels:\n",
    "    mask = test_labels_np == i\n",
    "    if mask.sum() > 0:\n",
    "        class_acc = (predictions[mask] == test_labels_np[mask]).sum() / mask.sum()\n",
    "        class_accuracies.append(class_acc)\n",
    "    else:\n",
    "        class_accuracies.append(0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(unique_labels)), class_accuracies, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('클래스', fontsize=12)\n",
    "plt.ylabel('정확도', fontsize=12)\n",
    "plt.title('클래스별 분류 정확도', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(unique_labels)), [f'Class_{i}' for i in unique_labels], rotation=45)\n",
    "plt.ylim([0, 1.1])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 값 표시\n",
    "for i, (bar, acc) in enumerate(zip(bars, class_accuracies)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-4: 예측 확신도 분포\n",
    "print(\"\\n[5-4] 예측 확신도 분포\")\n",
    "\n",
    "max_probs = probabilities_list.max(axis=1)\n",
    "correct_probs = probabilities_list[np.arange(len(predictions)), predictions]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 전체 예측 확신도\n",
    "axes[0].hist(max_probs, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('최대 예측 확률', fontsize=12)\n",
    "axes[0].set_ylabel('빈도', fontsize=12)\n",
    "axes[0].set_title('전체 예측 확신도 분포', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# 정확/오분류별 확신도\n",
    "correct_mask = predictions == test_labels_np\n",
    "axes[1].hist(max_probs[correct_mask], bins=30, alpha=0.7, label='정확', color='green', edgecolor='black')\n",
    "axes[1].hist(max_probs[~correct_mask], bins=30, alpha=0.7, label='오분류', color='red', edgecolor='black')\n",
    "axes[1].set_xlabel('최대 예측 확률', fontsize=12)\n",
    "axes[1].set_ylabel('빈도', fontsize=12)\n",
    "axes[1].set_title('정확/오분류별 예측 확신도', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ 시각화 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f33c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6단계: 종합 결과 요약\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6단계: 종합 결과 요약\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n[U-Net 모델 성능]\")\n",
    "print(f\"  모델 경로: {unet_model_path}\")\n",
    "print(f\"  결함 검출 정확도: {unet_accuracy:.4f}\")\n",
    "print(f\"  정밀도: {unet_precision:.4f}\")\n",
    "print(f\"  재현율: {unet_recall:.4f}\")\n",
    "print(f\"  F1 점수: {unet_f1_score:.4f}\")\n",
    "\n",
    "print(\"\\n[CNN 모델 성능]\")\n",
    "print(f\"  모델 경로: {cnn_model_path}\")\n",
    "print(f\"  결함 유형 분류 정확도: {cnn_accuracy:.4f}\")\n",
    "print(f\"  총 클래스 수: {num_classes}\")\n",
    "print(f\"  테스트 샘플 수: {len(test_labels_np)}\")\n",
    "\n",
    "print(\"\\n[테스트 데이터 정보]\")\n",
    "print(f\"  총 테스트 파일 수: {len(test_files)}\")\n",
    "print(f\"  U-Net 검출 완료: {len(unet_results)}개\")\n",
    "print(f\"  CNN 분류 가능 파일: {len(test_labels_np)}개\")\n",
    "\n",
    "print(\"\\n[모델 정보]\")\n",
    "print(f\"  U-Net 입력 shape: {unet_model.input_shape}\")\n",
    "print(f\"  U-Net 출력 shape: {unet_model.output_shape}\")\n",
    "print(f\"  CNN device: {device}\")\n",
    "print(f\"  CNN 파라미터 수: {sum(p.numel() for p in cnn_model.parameters()):,}\")\n",
    "\n",
    "print(\"\\n✓ 모든 테스트 완료!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
